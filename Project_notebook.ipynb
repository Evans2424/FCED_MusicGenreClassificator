{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['genres_original/rock/rock.00095.wav', 'genres_original/rock/rock.00022.wav', 'genres_original/rock/rock.00094.wav', 'genres_original/rock/rock.00076.wav', 'genres_original/rock/rock.00012.wav', 'genres_original/rock/rock.00062.wav', 'genres_original/rock/rock.00041.wav', 'genres_original/rock/rock.00046.wav', 'genres_original/rock/rock.00009.wav', 'genres_original/rock/rock.00097.wav', 'genres_original/rock/rock.00078.wav', 'genres_original/rock/rock.00080.wav', 'genres_original/rock/rock.00052.wav', 'genres_original/rock/rock.00011.wav', 'genres_original/rock/rock.00067.wav', 'genres_original/rock/rock.00077.wav', 'genres_original/rock/rock.00084.wav', 'genres_original/rock/rock.00072.wav', 'genres_original/rock/rock.00083.wav', 'genres_original/rock/rock.00042.wav', 'genres_original/rock/rock.00027.wav', 'genres_original/rock/rock.00090.wav', 'genres_original/rock/rock.00056.wav', 'genres_original/rock/rock.00051.wav', 'genres_original/rock/rock.00014.wav', 'genres_original/rock/rock.00026.wav', 'genres_original/rock/rock.00068.wav', 'genres_original/rock/rock.00061.wav', 'genres_original/rock/rock.00007.wav', 'genres_original/rock/rock.00021.wav', 'genres_original/rock/rock.00016.wav', 'genres_original/rock/rock.00069.wav', 'genres_original/rock/rock.00013.wav', 'genres_original/rock/rock.00060.wav', 'genres_original/rock/rock.00098.wav', 'genres_original/rock/rock.00001.wav', 'genres_original/rock/rock.00045.wav', 'genres_original/rock/rock.00047.wav', 'genres_original/rock/rock.00088.wav', 'genres_original/rock/rock.00064.wav', 'genres_original/rock/rock.00005.wav', 'genres_original/rock/rock.00044.wav', 'genres_original/rock/rock.00043.wav', 'genres_original/rock/rock.00033.wav', 'genres_original/rock/rock.00086.wav', 'genres_original/rock/rock.00023.wav', 'genres_original/rock/rock.00053.wav', 'genres_original/rock/rock.00029.wav', 'genres_original/rock/rock.00010.wav', 'genres_original/rock/rock.00089.wav', 'genres_original/rock/rock.00074.wav', 'genres_original/rock/rock.00032.wav', 'genres_original/rock/rock.00093.wav', 'genres_original/rock/rock.00039.wav', 'genres_original/rock/rock.00031.wav', 'genres_original/rock/rock.00024.wav', 'genres_original/rock/rock.00087.wav', 'genres_original/rock/rock.00091.wav', 'genres_original/rock/rock.00006.wav', 'genres_original/rock/rock.00085.wav', 'genres_original/rock/rock.00035.wav', 'genres_original/rock/rock.00004.wav', 'genres_original/rock/rock.00018.wav', 'genres_original/rock/rock.00073.wav', 'genres_original/rock/rock.00020.wav', 'genres_original/rock/rock.00048.wav', 'genres_original/rock/rock.00082.wav', 'genres_original/rock/rock.00063.wav', 'genres_original/rock/rock.00071.wav', 'genres_original/rock/rock.00037.wav', 'genres_original/rock/rock.00040.wav', 'genres_original/rock/rock.00081.wav', 'genres_original/rock/rock.00049.wav', 'genres_original/rock/rock.00017.wav', 'genres_original/rock/rock.00066.wav', 'genres_original/rock/rock.00092.wav', 'genres_original/rock/rock.00065.wav', 'genres_original/rock/rock.00025.wav', 'genres_original/rock/rock.00002.wav', 'genres_original/rock/rock.00075.wav', 'genres_original/rock/rock.00015.wav', 'genres_original/rock/rock.00038.wav', 'genres_original/rock/rock.00008.wav', 'genres_original/rock/rock.00000.wav', 'genres_original/rock/rock.00036.wav', 'genres_original/rock/rock.00030.wav', 'genres_original/rock/rock.00003.wav', 'genres_original/rock/rock.00099.wav', 'genres_original/rock/rock.00055.wav', 'genres_original/rock/rock.00050.wav', 'genres_original/rock/rock.00058.wav', 'genres_original/rock/rock.00059.wav', 'genres_original/rock/rock.00079.wav', 'genres_original/rock/rock.00019.wav', 'genres_original/rock/rock.00096.wav', 'genres_original/rock/rock.00057.wav', 'genres_original/rock/rock.00034.wav', 'genres_original/rock/rock.00070.wav', 'genres_original/rock/rock.00054.wav', 'genres_original/rock/rock.00028.wav']\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = 'genres_original'\n",
    "\n",
    "def load_audio_files(folder_path):\n",
    "    audio_files = []\n",
    "    for genre in os.listdir(folder_path):\n",
    "        genre_folder = os.path.join(folder_path, genre)\n",
    "        if os.path.isdir(genre_folder):\n",
    "            for file in os.listdir(genre_folder):\n",
    "                if file.endswith('.wav') and genre_folder == 'genres_original/rock':\n",
    "                    audio_files.append(os.path.join(genre_folder, file))\n",
    "    return audio_files\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo:  [123.046875]\n",
      "MFCCs shape: [-119.15098   107.44224   -10.973196   58.555363  -12.933258   26.83433\n",
      "  -17.646807   19.371737  -15.605269   13.570684  -16.67104    11.870044\n",
      "  -12.196166]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# Return the features\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mconcatenate([mfccs_mean, chroma_mean, spectral_contrast_mean, [zcr_mean, tempo]])\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgenres_original/rock/rock.00083.wav\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[48], line 31\u001b[0m, in \u001b[0;36mextract_features\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMFCCs shape:\u001b[39m\u001b[38;5;124m'\u001b[39m, mfccs_mean)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Return the features\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmfccs_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchroma_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspectral_contrast_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mzcr_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtempo\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "def extract_features(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=None)  # Load the audio file\n",
    "    \n",
    "    # Extract MFCCs\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    mfccs_mean = np.mean(mfccs, axis=1)\n",
    "    \n",
    "    # Extract Chroma feature\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    chroma_mean = np.mean(chroma, axis=1)\n",
    "    \n",
    "    # Spectral Contrast\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    spectral_contrast_mean = np.mean(spectral_contrast, axis=1)\n",
    "    \n",
    "    # Zero Crossing Rate\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    zcr_mean = np.mean(zcr)\n",
    "    \n",
    "    # Tempo\n",
    "    onset_env = librosa.onset.onset_strength(y=y, sr=sr)\n",
    "    tempo, _ = librosa.beat.beat_track(onset_envelope=onset_env, sr=sr)\n",
    "\n",
    "    print('Tempo: ' ,tempo)\n",
    "    print('MFCCs shape:', mfccs_mean)\n",
    "    \n",
    "\n",
    "    # Return the features\n",
    "    return np.concatenate([mfccs_mean, chroma_mean, spectral_contrast_mean, [zcr_mean, tempo]])\n",
    "    \n",
    "\n",
    "print(extract_features('genres_original/rock/rock.00083.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 4 has 2 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m feature_df\n\u001b[1;32m     26\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenres_original\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace with your actual path\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m features_df \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_feature_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mace_tools\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtools\u001b[39;00m; tools\u001b[38;5;241m.\u001b[39mdisplay_dataframe_to_user(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMusic Genre Features\u001b[39m\u001b[38;5;124m\"\u001b[39m, dataframe\u001b[38;5;241m=\u001b[39mfeatures_df)\n",
      "Cell \u001b[0;32mIn[33], line 18\u001b[0m, in \u001b[0;36mcreate_feature_dataset\u001b[0;34m(folder_path)\u001b[0m\n\u001b[1;32m     16\u001b[0m features \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m audio_files:\n\u001b[0;32m---> 18\u001b[0m     feature_vector \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# This should be 1D now\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(feature_vector)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Convert the list of features into a DataFrame\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[32], line 30\u001b[0m, in \u001b[0;36mextract_features\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     27\u001b[0m tempo, _ \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mbeat\u001b[38;5;241m.\u001b[39mbeat_track(onset_envelope\u001b[38;5;241m=\u001b[39monset_env, sr\u001b[38;5;241m=\u001b[39msr)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Combine all features into a single 1D feature vector\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m feature_vector \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmfccs_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# (13,)\u001b[39;49;00m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchroma_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# (12,)\u001b[39;49;00m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspectral_contrast_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# (6,)\u001b[39;49;00m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mzcr_mean\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# (1,)\u001b[39;49;00m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtempo\u001b[49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# (1,)\u001b[39;49;00m\n\u001b[1;32m     36\u001b[0m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(feature_vector\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m feature_vector\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genre-recognition-PQfsOjYy-py3.12/lib/python3.12/site-packages/numpy/_core/shape_base.py:356\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;66;03m# As a special case, dimension 0 of 1-dimensional arrays is \"horizontal\"\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arrs \u001b[38;5;129;01mand\u001b[39;00m arrs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrs, \u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, casting\u001b[38;5;241m=\u001b[39mcasting)\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 4 has 2 dimension(s)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def create_feature_dataset(folder_path):\n",
    "    audio_files = load_audio_files(folder_path)\n",
    "    features = []\n",
    "    for file in audio_files:\n",
    "        feature_vector = extract_features(file)  # This should be 1D now\n",
    "        features.append(feature_vector)\n",
    "    \n",
    "    # Convert the list of features into a DataFrame\n",
    "    feature_df = pd.DataFrame(features)\n",
    "    \n",
    "    return feature_df\n",
    "\n",
    "folder_path = 'genres_original'  # Replace with your actual path\n",
    "features_df = create_feature_dataset(folder_path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genre-recognition-PQfsOjYy-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
